# Chatbot com LangChain + Ollama v2.0

Este Ã© um aplicativo Streamlit que implementa um chatbot usando LangChain e Ollama para interaÃ§Ã£o com modelos de linguagem locais.

## ğŸš€ Funcionalidades

- Interface de chat intuitiva e responsiva
- IntegraÃ§Ã£o com Ollama para modelos locais
- HistÃ³rico de conversas persistente durante a sessÃ£o
- ConfiguraÃ§Ãµes personalizÃ¡veis do modelo
- Status de conexÃ£o em tempo real
- EstatÃ­sticas da conversa




### ğŸ¯ Prompt Personalizado
- **OpÃ§Ã£o de prompt padrÃ£o**: Alterne entre prompt personalizado e o padrÃ£o do LangChain

## ğŸ“‹ PrÃ©-requisitos

1. **Python 3.8+** instalado
2. **Ollama** instalado e rodando localmente
3. **Modelo DeepSeek R1 7B** (ou outro modelo de sua escolha) baixado no Ollama

### InstalaÃ§Ã£o do Ollama

```bash
# No Linux/macOS
curl -fsSL https://ollama.ai/install.sh | sh

# No Windows, baixe o instalador do site oficial
```

### Download do modelo

```bash
ollama pull deepseek-r1:7b
```

## ğŸ› ï¸ InstalaÃ§Ã£o

1. Clone ou baixe os arquivos do projeto
2. Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

## ğŸ¯ Como usar

1. **Inicie o Ollama** (se nÃ£o estiver rodando):
```bash
ollama serve
```

2. **Execute o aplicativo Streamlit**:
```bash
streamlit run streamlit_chatbot.py
```

3. **Acesse o aplicativo** no navegador (geralmente `http://localhost:8501`)

5. **Comece a conversar** digitando mensagens no campo de entrada (agora posicionado abaixo das mensagens)

## âš™ï¸ ConfiguraÃ§Ãµes

### Sidebar

#### ğŸ”§ .env
    LLM_PROPMPT=VocÃª Ã© um assistente Ãºtil e amigÃ¡vel. Responda de forma clara e concisa.
    OLLAMA_URL=http://localhost:11434
    BASE_URL=http://localhost:11434/api/generate


#### ğŸ¯ OpÃ§Ãµes
- **Usar prompt padrÃ£o do LangChain**: Checkbox para alternar entre prompt personalizado e padrÃ£o
- **AI Think**: Checkbox para mostrar o pensamento da AI atÃ© a resposta.

#### ğŸ—‘ï¸ Controles
- **Limpar HistÃ³rico**: Remove todas as mensagens da conversa atual

### Status AvanÃ§ado

#### ğŸ“Š InformaÃ§Ãµes em Tempo Real
- **Contador de Mensagens**: Total de mensagens na conversa
- **Modelo Atual**: Exibe o modelo em uso

#### ğŸ“ˆ EstatÃ­sticas Detalhadas
- **Mensagens do UsuÃ¡rio**: Contador especÃ­fico
- **Respostas da IA**: Contador especÃ­fico
- **InformaÃ§Ãµes do Modelo**: Detalhes tÃ©cnicos

## ğŸ”§ Estrutura do CÃ³digo

### `CustomLLMLangChain`

Classe personalizada que herda de `LLM` do LangChain:

- **Campos**: `model` (nome do modelo) e `base_url` (URL do Ollama)
- **MÃ©todo `_call`**: Faz requisiÃ§Ãµes HTTP para o Ollama
- **Tratamento de Erros**: Captura erros de conexÃ£o, timeout e outros
- **Compatibilidade Pydantic**: InicializaÃ§Ã£o correta para validaÃ§Ã£o


### `chat_bot`
LÃ³gica e regras do chat com a llm
- **ConfiguraÃ§Ãµes DinÃ¢micas**: Sidebar com opÃ§Ãµes personalizÃ¡veis
- **Interface de Chat**: Layout otimizado com `st.chat_message` e `st.chat_input`
- **Gerenciamento de Estado**: Usando `st.session_state` para persistÃªncia
- **Monitoramento**: Status de conexÃ£o e mÃ©tricas detalhadas



## ğŸ“ PersonalizaÃ§Ã£o

### Exemplos de Prompts Personalizados

#### Assistente TÃ©cnico
```
VocÃª Ã© um especialista em programaÃ§Ã£o e tecnologia. Responda de forma tÃ©cnica e precisa, fornecendo exemplos de cÃ³digo quando apropriado.
```

#### Assistente Criativo
```
VocÃª Ã© um assistente criativo e inspirador. Use linguagem poÃ©tica e imaginativa, sempre buscando soluÃ§Ãµes inovadoras e fora da caixa.
```

#### Assistente Formal
```
VocÃª Ã© um assistente profissional e formal. Use linguagem corporativa, seja conciso e objetivo em suas respostas.
```

### Adicionando Novos Modelos

1. Baixe o modelo no Ollama:
```bash
ollama pull nome-do-modelo
```

2. Altere o campo "Nome do Modelo" na sidebar

### Modificando a Interface

- **Cores e Tema**: Edite o CSS no final do arquivo
- **Layout**: Ajuste as colunas e containers
- **Funcionalidades**: Adicione novos widgets na sidebar

### ConfiguraÃ§Ãµes AvanÃ§adas

- **Memory**: Modifique o tipo de memÃ³ria do LangChain
- **Prompts**: Use templates mais complexos com variÃ¡veis
- **Streaming**: Implemente respostas em tempo real

## ğŸ”„ Changelog

### v2.0
- âœ… Chat input movido para baixo das mensagens
- âœ… Indicador visual do prompt ativo
- âœ… EstatÃ­sticas detalhadas da conversa
- âœ… Layout otimizado e mais intuitivo
- âœ… Mensagem de boas-vindas personalizada

### v1.0
- âœ… Interface bÃ¡sica de chat
- âœ… IntegraÃ§Ã£o com Ollama
- âœ… ConfiguraÃ§Ãµes de modelo
- âœ… Status de conexÃ£o
- âœ… HistÃ³rico de conversas

## ğŸ¤ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para:

- Reportar bugs
- Sugerir melhorias
- Enviar pull requests
- Compartilhar feedback

---



